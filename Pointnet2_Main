import torch
import torch.nn as nn
import torch.nn.functional as F
from time import time
import numpy as np
import open3d as o3d
import os
import torch.utils.data as data
from matplotlib import pyplot as plt
import torch.optim as optim
from torchsummary import summary


def parse_train_dataset_aug3(file_name, NUM_POINTS, DATA_DIR):
    train_points = []
    train_labels = []
    train_class = []
    clip = 0.05
    sigma=0.01
    #print(f'file_name:{file_name}')
    file = open(file_name)

    for line in file: 
        #print(f'line:{line}')
        words = line.split()
        #print(os.path.join(DATA_DIR, words[0]))
        pcd = o3d.io.read_point_cloud(os.path.join(DATA_DIR, words[0]))
        points1 = np.asarray(pcd.points)
        centroid = np.mean(points1, axis=0)
        points1 -= centroid
        furthest_distance = np.max(np.sqrt(np.sum(abs(points1)**2, axis=-1)))
        points1 /= furthest_distance
        rng = np.random.default_rng()
        points2 = rng.permutation(np.concatenate((points1, np.asarray(pcd.colors)), axis=1))
        noOffPCDs = int( points2.shape[0] / NUM_POINTS )
        for i in range(noOffPCDs):
            start = i * NUM_POINTS
            end = (i + 1) * NUM_POINTS
            #print(f'start: {start} end: {end}')
            points = points2[start:end,:]  
            N, C = points.shape
            #assert(clip > 0)
            jittered_data = np.clip(sigma * np.random.randn(N, C), -1*clip, clip)
            #print(jittered_data.shape)
            jittered_data += points
            rotation_angle = np.random.uniform() * 2 * np.pi  # Random angle in [0, 2π]
            #print(rotation_angle)
            cosval = np.cos(rotation_angle)
            sinval = np.sin(rotation_angle)
            # Rotation matrix around the y-axis
            rotation_matrix = np.array([[cosval, 0, sinval],
                                        [0, 1, 0],
                                        [-sinval, 0, cosval]])
            # Apply rotation
            rotated_points = np.dot(jittered_data[:,0:3], rotation_matrix)
            rotated_points = np.concatenate((rotated_points, jittered_data[:,3:6]), axis=1)
            #print(jittered_data.shape)
            train_points.append(rotated_points)
            #print(jittered_data.shape)
            stdv = np.random.randint(-2, 2)
            train_labels.append(float(words[1]) + stdv)
            train_class.append(float(words[2]))
            #break
        #break
    return (
        np.array(train_points),
        np.array(train_labels),
        np.array(train_class),
    )

def parse_test_dataset_aug2(file_name, NUM_POINTS, DATA_DIR):
    test_points = []
    test_labels = []
    test_class = []
    clip = 0.05
    sigma=0.01
    file = open(file_name)
    for line in file: 
        #print(f'line:{line}')
        words = line.split()
        
        pcd = o3d.io.read_point_cloud(os.path.join(DATA_DIR, words[0]))
        #points1 = np.asarray(pcd.colors)
        points1 = np.asarray(pcd.points)
        centroid = np.mean(points1, axis=0)
        points1 -= centroid
        furthest_distance = np.max(np.sqrt(np.sum(abs(points1)**2, axis=-1)))
        points1 /= furthest_distance
        rng = np.random.default_rng()
        #points2 = rng.permutation(points1)
        points2 = rng.permutation(np.concatenate((points1, np.asarray(pcd.colors)), axis=1))
        #print(points2.shape)
        points = points2[0:NUM_POINTS,:]  
        N, C = points.shape
        #assert(clip > 0)
        jittered_data = np.clip(sigma * np.random.randn(N, C), -1*clip, clip)
        #print(jittered_data.shape)
        jittered_data += points
        #print(jittered_data.shape)
        test_points.append(jittered_data)
        test_labels.append(float(words[1]))
        test_class.append(float(words[2]))
    
    return (
        np.array(test_points),
        np.array(test_labels),
        np.array(test_class),
    )

class PointCloudDataset(data.Dataset):
    def __init__(self, data, labels, classes):
        self.data = data
        self.labels = labels
        self.classes = classes

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        point_set = self.data[idx]
        label = self.labels[idx]
        classes = self.classes[idx]
        return point_set, label, classes
        
def timeit(tag, t):
    print("{}: {}s".format(tag, time() - t))
    return time()

def pc_normalize(pc):
    l = pc.shape[0]
    centroid = np.mean(pc, axis=0)
    pc = pc - centroid
    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))
    pc = pc / m
    return pc

def square_distance(src, dst):
    """
    Calculate Euclid distance between each two points.

    src^T * dst = xn * xm + yn * ym + zn * zm；
    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;
    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;
    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2
         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst

    Input:
        src: source points, [B, N, C]
        dst: target points, [B, M, C]
    Output:
        dist: per-point square distance, [B, N, M]
    """
    B, N, _ = src.shape
    _, M, _ = dst.shape
    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))
    dist += torch.sum(src ** 2, -1).view(B, N, 1)
    dist += torch.sum(dst ** 2, -1).view(B, 1, M)
    return dist


def index_points(points, idx):
    """

    Input:
        points: input points data, [B, N, C]
        idx: sample index data, [B, S]
    Return:
        new_points:, indexed points data, [B, S, C]
    """
    #print('In index points')
    #print('Points shape', points.shape)
    #print('idx shape', idx.shape)
    device = points.device
    B = points.shape[0]
    view_shape = list(idx.shape)
    view_shape[1:] = [1] * (len(view_shape) - 1)
    repeat_shape = list(idx.shape)
    repeat_shape[0] = 1
    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)
    #print('batch_indices',batch_indices.shape)
    new_points = points[batch_indices, idx, :]
    #print('new_points',new_points.shape)
    return new_points


def farthest_point_sample(xyz, npoint):
    """
    Input:
        xyz: pointcloud data, [B, N, 3]
        npoint: number of samples
    Return:
        centroids: sampled pointcloud index, [B, npoint]
    """
    device = xyz.device
    B, N, C = xyz.shape
    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)
    distance = torch.ones(B, N).to(device) * 1e10
    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)
    batch_indices = torch.arange(B, dtype=torch.long).to(device)
    for i in range(npoint):
        centroids[:, i] = farthest
        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)
        dist = torch.sum((xyz - centroid) ** 2, -1)
        mask = dist < distance
        distance[mask] = dist[mask]
        farthest = torch.max(distance, -1)[1]
    return centroids

'''from pytorch3d.ops import ball_query

def query_ball_point(radius, nsample, xyz, new_xyz):
    dists, idx, nn = ball_query( p1=new_xyz, p2=xyz, K=nsample,radius = radius)
    return idx'''

def query_ball_point(radius, nsample, xyz, new_xyz):
    """
    Input:
        radius: local region radius
        nsample: max sample number in local region
        xyz: all points, [B, N, 3]
        new_xyz: query points, [B, S, 3]
    Return:
        group_idx: grouped points index, [B, S, nsample]
    """
    #print('In query ball point')
    device = xyz.device
    B, N, C = xyz.shape
    _, S, _ = new_xyz.shape
    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])
    sqrdists = square_distance(new_xyz, xyz)
    group_idx[sqrdists > radius ** 2] = N-1
    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]
    mask = group_idx == N
    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])
    #print('Group mask', mask.shape)
    #print('Group frist',group_first.shape)
    group_idx[mask] = group_first[mask]
    return group_idx


def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):
    """
    Input:
        npoint:
        radius:
        nsample:
        xyz: input points position data, [B, N, 3]
        points: input points data, [B, N, D]
    Return:
        new_xyz: sampled points position data, [B, npoint, nsample, 3]
        new_points: sampled points data, [B, npoint, nsample, 3+D]
    """
    B, N, C = xyz.shape
    S = npoint
    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]
    new_xyz = index_points(xyz, fps_idx)
    idx = query_ball_point(radius, nsample, xyz, new_xyz)
    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]
    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)

    if points is not None:
        grouped_points = index_points(points, idx)
        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, C+D]
    else:
        new_points = grouped_xyz_norm
    if returnfps:
        return new_xyz, new_points, grouped_xyz, fps_idx
    else:
        return new_xyz, new_points


def sample_and_group_all(xyz, points):
    """
    Input:
        xyz: input points position data, [B, N, 3]
        points: input points data, [B, N, D]
    Return:
        new_xyz: sampled points position data, [B, 1, 3]
        new_points: sampled points data, [B, 1, N, 3+D]
    """
    device = xyz.device
    B, N, C = xyz.shape
    new_xyz = torch.zeros(B, 1, C).to(device)
    grouped_xyz = xyz.view(B, 1, N, C)
    if points is not None:
        new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)
    else:
        new_points = grouped_xyz
    return new_xyz, new_points


class PointNetSetAbstraction(nn.Module):
    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):
        super(PointNetSetAbstraction, self).__init__()
        self.npoint = npoint
        self.radius = radius
        self.nsample = nsample
        self.mlp_convs = nn.ModuleList()
        self.mlp_bns = nn.ModuleList()
        last_channel = in_channel
        for out_channel in mlp:
            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))
            self.mlp_bns.append(nn.BatchNorm2d(out_channel))
            last_channel = out_channel
        self.group_all = group_all

    def forward(self, xyz, points):
        """
        Input:
            xyz: input points position data, [B, C, N]
            points: input points data, [B, D, N]
        Return:
            new_xyz: sampled points position data, [B, C, S]
            new_points_concat: sample points feature data, [B, D', S]
        """
        xyz = xyz.permute(0, 2, 1)
        if points is not None:
            points = points.permute(0, 2, 1)

        if self.group_all:
            new_xyz, new_points = sample_and_group_all(xyz, points)
        else:
            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)
        # new_xyz: sampled points position data, [B, npoint, C]
        # new_points: sampled points data, [B, npoint, nsample, C+D]
        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]
        for i, conv in enumerate(self.mlp_convs):
            bn = self.mlp_bns[i]
            new_points =  F.relu(bn(conv(new_points)))

        new_points = torch.max(new_points, 2)[0]
        new_xyz = new_xyz.permute(0, 2, 1)
        return new_xyz, new_points


class PointNetSetAbstractionMsg(nn.Module):
    def __init__(self, npoint, radius_list, nsample_list, in_channel, mlp_list):
        super(PointNetSetAbstractionMsg, self).__init__()
        self.npoint = npoint
        self.radius_list = radius_list
        self.nsample_list = nsample_list
        self.conv_blocks = nn.ModuleList()
        self.bn_blocks = nn.ModuleList()
        for i in range(len(mlp_list)):
            convs = nn.ModuleList()
            bns = nn.ModuleList()
            last_channel = in_channel + 3
            for out_channel in mlp_list[i]:
                convs.append(nn.Conv2d(last_channel, out_channel, 1))
                bns.append(nn.BatchNorm2d(out_channel))
                last_channel = out_channel
            self.conv_blocks.append(convs)
            self.bn_blocks.append(bns)

    def forward(self, xyz, points):
        """
        Input:
            xyz: input points position data, [B, C, N]
            points: input points data, [B, D, N]
        Return:
            new_xyz: sampled points position data, [B, C, S]
            new_points_concat: sample points feature data, [B, D', S]
        """
        xyz = xyz.permute(0, 2, 1)
        if points is not None:
            points = points.permute(0, 2, 1)

        B, N, C = xyz.shape
        #print('B N C',B,N,C)
        S = self.npoint
        new_xyz = index_points(xyz, farthest_point_sample(xyz, S))
        new_points_list = []
        for i, radius in enumerate(self.radius_list):
            K = self.nsample_list[i]
            #print('radius',radius, K)
            group_idx = query_ball_point(radius, K, xyz, new_xyz)
            #print('after query')
            grouped_xyz = index_points(xyz, group_idx)
            grouped_xyz -= new_xyz.view(B, S, 1, C)
            if points is not None:
                grouped_points = index_points(points, group_idx)
                grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)
            else:
                grouped_points = grouped_xyz

            grouped_points = grouped_points.permute(0, 3, 2, 1)  # [B, D, K, S]
            for j in range(len(self.conv_blocks[i])):
                conv = self.conv_blocks[i][j]
                bn = self.bn_blocks[i][j]
                grouped_points =  F.relu(bn(conv(grouped_points)))
            new_points = torch.max(grouped_points, 2)[0]  # [B, D', S]
            new_points_list.append(new_points)

        new_xyz = new_xyz.permute(0, 2, 1)
        new_points_concat = torch.cat(new_points_list, dim=1)
        return new_xyz, new_points_concat


class PointNetFeaturePropagation(nn.Module):
    def __init__(self, in_channel, mlp):
        super(PointNetFeaturePropagation, self).__init__()
        self.mlp_convs = nn.ModuleList()
        self.mlp_bns = nn.ModuleList()
        last_channel = in_channel
        for out_channel in mlp:
            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))
            self.mlp_bns.append(nn.BatchNorm1d(out_channel))
            last_channel = out_channel

    def forward(self, xyz1, xyz2, points1, points2):
        """
        Input:
            xyz1: input points position data, [B, C, N]
            xyz2: sampled input points position data, [B, C, S]
            points1: input points data, [B, D, N]
            points2: input points data, [B, D, S]
        Return:
            new_points: upsampled points data, [B, D', N]
        """
        xyz1 = xyz1.permute(0, 2, 1)
        xyz2 = xyz2.permute(0, 2, 1)

        points2 = points2.permute(0, 2, 1)
        B, N, C = xyz1.shape
        _, S, _ = xyz2.shape

        if S == 1:
            interpolated_points = points2.repeat(1, N, 1)
        else:
            dists = square_distance(xyz1, xyz2)
            dists, idx = dists.sort(dim=-1)
            dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]

            dist_recip = 1.0 / (dists + 1e-8)
            norm = torch.sum(dist_recip, dim=2, keepdim=True)
            weight = dist_recip / norm
            interpolated_points = torch.sum(index_points(points2, idx) * weight.view(B, N, 3, 1), dim=2)

        if points1 is not None:
            points1 = points1.permute(0, 2, 1)
            new_points = torch.cat([points1, interpolated_points], dim=-1)
        else:
            new_points = interpolated_points

        new_points = new_points.permute(0, 2, 1)
        for i, conv in enumerate(self.mlp_convs):
            bn = self.mlp_bns[i]
            new_points = F.relu(bn(conv(new_points)))
        return new_points

import torch.nn as nn
import torch.nn.functional as F
#from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction

class get_model(nn.Module):
    def __init__(self, num_class=5, normal_channel=True):
        super(get_model, self).__init__()
        in_channel = 6 if normal_channel else 3
        self.normal_channel = normal_channel
        
        # PointNet Set Abstraction Layers
        self.sa1 = PointNetSetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)
        self.sa2 = PointNetSetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)
        self.sa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)
        
        # Shared Fully Connected Layers
        self.fc1 = nn.Linear(1024, 512)
        self.bn1 = nn.BatchNorm1d(512)
        self.drop1 = nn.Dropout(0.4)
        
        self.fc2 = nn.Linear(512, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.drop2 = nn.Dropout(0.4)
        
        # Separate heads for classification and regression
        self.class_fc = nn.Linear(256, num_class)  # Classification head
        self.reg_fc = nn.Linear(256 + num_class, 1)  # Regression head

    def forward(self, xyz):
        """
        Args:
            xyz: Input point cloud data, shape [B, N, C].
            task_condition: Task indicator tensor (e.g., [B, 1]), optional.
        """
        B, _, _ = xyz.shape
        if self.normal_channel:
            norm = xyz[:, 3:, :]
            xyz = xyz[:, :3, :]
        else:
            norm = None
        
        # PointNet feature extraction
        l1_xyz, l1_points = self.sa1(xyz, norm)
        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)
        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)
        
        x = l3_points.view(B, 1024)
        x = self.drop1(F.relu(self.bn1(self.fc1(x))))
        shared_features = self.drop2(F.relu(self.bn2(self.fc2(x))))
        
        # Multi-task outputs
        classification_output = self.class_fc(shared_features)
        class_probs = F.softmax(classification_output, -1)
        regression_input = torch.cat([shared_features, class_probs], dim=-1)
        #print(f'regression_input:{regression_input.shape}')
        regression_output = self.reg_fc(regression_input)
        #print(f'regression_output:{regression_output.shape}')
        #print(f'class_probs:{class_probs.shape}')
        return classification_output, regression_output

class get_loss(nn.Module):
    def __init__(self):
        super(get_loss, self).__init__()

    def forward(self, pred, target):
        total_loss = F.nll_loss(pred, target)

        return total_loss
        
def SmoothL1Loss(y_true, y_pred):
        #print(f'Y pred:{y_pred}')
        #print(f'Y true:{y_true}')
        abs_loss = torch.abs(y_true - y_pred)
        square_loss = 0.5 * (y_true - y_pred) ** 2
        res = torch.where(torch.less(abs_loss, 1.0), square_loss, abs_loss - 0.5)
        return torch.mean(res, axis=-1)

def rmse(y_true, y_pred):
    return torch.sqrt(torch.mean((y_true - y_pred) ** 2))

def mbe(y_pred, y_true):
    return torch.mean(y_pred - y_true)

def train(model, train_dataloader, test_dataloader, num_epochs=100):
    
    
    #criterion = nn.SmoothL1Loss()
    #criterion = SmoothL1Loss()
    #criterion = get_loss()
    criterion = nn.CrossEntropyLoss()

    pavg_rmse = 10000
    pavg_loss = 10000
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    #current_directory = os.getcwd()
    for epoch in range(num_epochs):
        model.train()
        train_epoch_loss = 0.0
        train_epoch_rmse = 0.0
        for i, (train_points, train_labels, train_class) in enumerate(train_dataloader):
            optimizer.zero_grad()
            #print(train_labels)
            train_points = train_points.permute(0, 2, 1).float()
                       
            class_logits, reg_output = model(train_points)
            class_logits = class_logits.float()
            reg_output = reg_output.float()
            train_class = train_class.long()
            class_loss = criterion(class_logits, train_class)
            reg_output = reg_output.squeeze()
            train_labels = train_labels.float()
            regression_loss = SmoothL1Loss(train_labels, reg_output)
            regression_loss = regression_loss.float()
             # Combine losses
            train_loss = 1.0 * class_loss + 0.5 * regression_loss  # Adjust weights as needed
        
            train_loss.backward()
            optimizer.step()

            train_epoch_rmse += rmse(train_labels, reg_output).item()
            train_epoch_loss += train_loss.item()
            
            '''if i % 10 == 9:    # Print every 10 mini-batches
                print(f'[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss / 10:.3f}')
                running_loss = 0.0'''
        avg_loss = train_epoch_loss / len(train_dataloader)
        avg_rmse = train_epoch_rmse / len(train_dataloader)
        print(f'Training Epoch {epoch+1}/{num_epochs}  Smooth L1 Loss is: {avg_loss}  RMSE: {avg_rmse}')
    
        model.eval()
        test_epoch_loss = 0.0
        test_epoch_rmse = 0.0
        for i, (test_points, test_labels, test_class) in enumerate(test_dataloader):
            test_points = test_points.permute(0, 2, 1).float()
            #test_outputs = model(test_points).float()
            test_logits, test_reg = model(test_points)
            test_logits = test_logits.float()
            test_reg = test_reg.float()
            test_class = test_class.long()
            class_loss = criterion(test_logits, test_class)
            test_reg = test_reg.squeeze()
            test_labels = test_labels.float()
            reg_loss = SmoothL1Loss(test_labels, test_reg)
            reg_loss = reg_loss.float()
            test_epoch_rmse += rmse(test_labels, test_reg).item()
             # Combine losses
            test_loss = 1.0 * class_loss + 0.5 * reg_loss  # Adjust weights as needed
        
            test_epoch_loss += test_loss.item()
            
        avg_loss = test_epoch_loss / len(test_dataloader)
        avg_rmse = test_epoch_rmse / len(test_dataloader)
        print(f'Validation Smooth L1 Loss is: {avg_loss}  RMSE: {avg_rmse}')
        # Save the model's state dictionary
        if(pavg_rmse > avg_rmse and pavg_loss > avg_loss):
            model_name = 'PointNet_plus2_'+str(epoch)+'_multi_colorshape.pth'
            print(model_name)
            torch.save(model.state_dict(), model_name)
            pavg_loss = avg_loss
            pavg_rmse = avg_rmse
    print('Finished Training and Evaluation')
    return model

def prepareData( DATA_DIR, NUM_POINTS, device, BATCH_SIZE ):

    #visualizePCD( DATA_DIR, NUM_POINTS)
    
    #train_points, train_labels = parse_train_dataset_aug3(DATA_DIR + 'Train_list.txt', NUM_POINTS, DATA_DIR)
    train_points, train_labels, train_class = parse_train_dataset_aug3('D:/Riseholm_Wheat_Biomass_Train_Multi.txt', NUM_POINTS, DATA_DIR)
    #test_points, test_labels = parse_test_dataset_aug2(DATA_DIR + 'Test_list.txt', NUM_POINTS, DATA_DIR)
    test_points, test_labels, test_class = parse_test_dataset_aug2('D:/Riseholm_Wheat_Biomass_Test_Multi.txt', NUM_POINTS, DATA_DIR)    
    # Convert numpy arrays to PyTorch tensors
    data_tensor = torch.tensor(train_points).to(device)
    labels_tensor = torch.tensor(train_labels).to(device)
    class_tensor = torch.tensor(train_class).to(device)

    print(f'Training data shape:{data_tensor.shape}')
    print(f'Training labels shape:{labels_tensor.shape}')
    print(f'Training labels shape:{class_tensor.shape}')

    # Example usage
    # Instantiate the custom dataset
    dataset = PointCloudDataset(data_tensor, labels_tensor, class_tensor)

    # Create a DataLoader
    train_dataloader = data.DataLoader(dataset, batch_size=24, shuffle=True)

    # Convert numpy arrays to PyTorch tensors
    data_tensor = torch.tensor(test_points).to(device)
    labels_tensor = torch.tensor(test_labels).to(device)
    class_tensor = torch.tensor(test_class).to(device)

    print(f'Test data shape:{data_tensor.shape}')
    print(f'Test labels shape:{labels_tensor.shape}')
    print(f'Test labels shape:{class_tensor.shape}')
    
    # Example usage
    # Instantiate the custom dataset
    dataset = PointCloudDataset(data_tensor, labels_tensor, class_tensor)

    # Create a DataLoader
    test_dataloader = data.DataLoader(dataset, batch_size=24, shuffle=True)
    
    return train_dataloader, test_dataloader

def prepareData_Eval( DATA_DIR, NUM_POINTS, device, BATCH_SIZE ):

    #visualizePCD( DATA_DIR, NUM_POINTS)
    
    #train_points, train_labels = parse_train_dataset_aug3(DATA_DIR + 'Train_list.txt', NUM_POINTS, DATA_DIR)
    train_points, train_labels = parse_test_dataset_aug2('D:/Riseholm_Wheat_Biomass_Train.txt', NUM_POINTS, DATA_DIR)
    #test_points, test_labels = parse_test_dataset_aug2(DATA_DIR + 'Test_list.txt', NUM_POINTS, DATA_DIR)
    test_points, test_labels = parse_test_dataset_aug2('D:/Riseholm_Wheat_Biomass_Test.txt', NUM_POINTS, DATA_DIR)    
    # Convert numpy arrays to PyTorch tensors
    data_tensor = torch.tensor(train_points).to(device)
    labels_tensor = torch.tensor(train_labels).to(device)

    print(f'Training data shape:{data_tensor.shape}')
    print(f'Training labels shape:{labels_tensor.shape}')

    # Example usage
    # Instantiate the custom dataset
    dataset = PointCloudDataset(data_tensor, labels_tensor)

    # Create a DataLoader
    train_dataloader = data.DataLoader(dataset, batch_size=24, shuffle=True)

    # Convert numpy arrays to PyTorch tensors
    data_tensor = torch.tensor(test_points).to(device)
    labels_tensor = torch.tensor(test_labels).to(device)

    print(f'Test data shape:{data_tensor.shape}')
    print(f'Test labels shape:{labels_tensor.shape}')
    
    # Example usage
    # Instantiate the custom dataset
    dataset = PointCloudDataset(data_tensor, labels_tensor)

    # Create a DataLoader
    test_dataloader = data.DataLoader(dataset, batch_size=24, shuffle=True)
    
    return train_dataloader, test_dataloader 

def main():
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(device)
    #model = C8SteerableCNN().to(device)
    NUM_POINTS = 2048
    NUM_CLASSES = 5
    BATCH_SIZE = 30
    #DATA_DIR = ("D:/Dataset/Yanco_TC_2019_HI-pcd/")
    DATA_DIR = ("D:/")
    flag = 'train'
    
    if (flag=='train'): 

        train_dataloader, test_dataloader = prepareData( DATA_DIR, NUM_POINTS, device, BATCH_SIZE )   
        model = get_model(NUM_CLASSES, normal_channel=True).to(device)
        model = train(model, train_dataloader, test_dataloader, num_epochs=100)

    elif (flag=='eval'):
        #DATA_DIR = ("D:/")
        train_dataloader, test_dataloader = prepareData_Eval( DATA_DIR, NUM_POINTS, device, BATCH_SIZE )
        model = get_model(NUM_CLASSES, normal_channel=False).to(device)
        model.load_state_dict(torch.load('C:/Users/jaspr/PointNet_plus2_26_color.pth'))
        model.eval()
        test_epoch_loss = 0.0
        test_epoch_rmse = 0.0
        train_mbe = 0.0
        for i, (test_points, test_labels) in enumerate(train_dataloader):
            test_points = test_points.permute(0, 2, 1).float()
            test_outputs = model(test_points).float()
            #print(test_outputs)
            test_outputs = test_outputs.squeeze()
            test_labels = test_labels.float()
            test_loss = SmoothL1Loss(test_labels, test_outputs)
            test_loss = test_loss.float()
    
            test_epoch_rmse += rmse(test_labels, test_outputs).item()
            train_mbe += mbe(test_outputs, test_labels).item()
            #print(f'test_epoch_rmse:{test_epoch_rmse/len(test_dataloader)} data legth:{len(test_dataloader)}')
            test_epoch_loss += test_loss.item()
            #print(test_epoch_rmse)            
        avg_loss = test_epoch_loss / len(test_dataloader)
        avg_rmse = test_epoch_rmse / len(test_dataloader)
        print(f'Validation Smooth L1 Loss is: {avg_loss}  RMSE: {avg_rmse} MBE:{train_mbe}')

        test_epoch_loss = 0.0
        test_epoch_rmse = 0.0
        test_epoch_rmse_mbe = 0.0
        for i, (test_points, test_labels) in enumerate(test_dataloader):
            test_points = test_points.permute(0, 2, 1).float()
            test_outputs = model(test_points).float()
            print(test_outputs)
            test_outputs = test_outputs.squeeze()
            test_labels = test_labels.float()
            test_loss = SmoothL1Loss(test_labels, test_outputs)
            test_loss = test_loss.float()
    
            test_epoch_rmse += rmse(test_labels, test_outputs).item()
            test_epoch_rmse_mbe += rmse(test_labels, test_outputs+(-1.0*train_mbe)).item()
            #print(f'test_epoch_rmse:{test_epoch_rmse/len(test_dataloader)} data legth:{len(test_dataloader)}')
            test_epoch_loss += test_loss.item()
            #print(test_epoch_rmse)            
        avg_loss = test_epoch_loss / len(test_dataloader)
        avg_rmse = test_epoch_rmse / len(test_dataloader)
        avg_rmse_mbe = test_epoch_rmse_mbe / len(test_dataloader)
        print(f'Validation Smooth L1 Loss is: {avg_loss}  RMSE: {avg_rmse} RMSE+MBE: {avg_rmse_mbe}')

    elif (flag=='finetune'):

        DATA_DIR = ("D:/")
        train_dataloader, test_dataloader = prepareData( DATA_DIR, NUM_POINTS, device, BATCH_SIZE )
        model = get_model(NUM_CLASSES, normal_channel=True).to(device)
        model.load_state_dict(torch.load('C:/Users/jaspr/PointNet_plus2_27_color.pth'))
        model = train(model, train_dataloader, test_dataloader, num_epochs=20)
        #torch.save(model.state_dict(), 'PointNet_plus2_Riseholme_shapecolor_GS5.pth')

    
if __name__ == '__main__':
    main()

